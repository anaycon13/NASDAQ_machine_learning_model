# NASDAQ_machine_learning_model
Authors: Thor Mead, Arya Bhansali, and Anay Contractor

We trained a multilinear regression machine learning model to predict NASDAQ movements using alternative data. We first aim to backtest this model, and then see if we can extrapolate it for future events. The goal is to see if non-traditional financial data (credit card balances, web traffic, loan delinquencies, consumer price indices, etc.) can be used to create statistically significant models for stock market analysis and prediction. Eventually, we hope to increase the number of relevant variables, search for new parameters, and strengthen the mathematical and statistical foundations of our model. We have stored all of the raw CSV data in the folder called RawData within this project. We obtained our data from https://fred.stlouisfed.org/.

Before any testing and analysis were done, we first had to clean up our data. When looking through all of the CSV files, we saw that the data had different time blocks. We saw that since most of the FRED data is quarterly along with the fact that most traditional financial reports are quarterly releases, we decided that standardizing our data to quarterly would make the most sense. Standardizing our data would eliminate unnecessary confusion for the model and help us evaluate as necessary for the models we are using. We also noticed that not all of the data were collected during the same timeframes. To accommodate for this, we decided to only collect data in which there was commonality amongst all the files for the dates so that we don't have a lot of null or zero value entries for data that the FRED didn't have on record for the specific variables that we are measuring in this case. 

The next step was testing multicollinearity in the data. This is an important step for training any model as multicollinearity can lead to a reduction in the statistical significance of any results. Although regression models have penalties for multicollinearity, this code systematically shows how one can assess multicollinearity between independent variables before choosing a model with all the variables as necessary. The Variance Inflation Factor (VIF) approach allows us to clearly show variable refactoring to get the necessary variables for us to use for modeling and analysis.

Using this analysis, it was clear that the standard Linear Regression model would produce high levels of multicollinearity from the test. To account for this, we had to use either the LASSO or Ridge Regression models, which we decided to evaluate for both here. Running the model around 10,000 times, we saw that there was not much difference between the LASSO and Ridge in terms of errors though it was shown to be more accurate for the LASSO Regression model. 

The main obstacle was the fact that our data transformations resulted in only being able to use only 12 variables and 38 data points since we used the data from 2013Q1 to 2022Q3. This posed challenges since there was not much we could do to predict values that happened during time periods such as COVID, as those produced the most significant errors in the model results. Along with this, there was not enough data for us to have larger trends that we could've looked into.


 
